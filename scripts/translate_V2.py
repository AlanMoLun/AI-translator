# translate.py
# ----------------------------------------
# ä» glossary.pkl + glossary.index åŠ è½½è¯åº“
# ä½¿ç”¨å‘é‡åŒ¹é…æ‰¾åˆ°ç›¸å…³æœ¯è¯­
# å¹¶ç”¨ OpenAI ç¿»è¯‘è¾“å…¥å¥å­ï¼Œè‡ªåŠ¨å‚è€ƒæœ¯è¯­è¡¨

import os
import json
import pickle
import faiss
import numpy as np
import pandas as pd
from openai import OpenAI

# å®šä¹‰ç›®å½•
projectRoot = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) + "\\"
binFolder = os.path.join(projectRoot, "bin") + "\\"
glossariesFolder = os.path.join(projectRoot, "glossaries") + "\\"
translationFolder = os.path.join(projectRoot, "translation") + "\\"

# =====================================================
# 1ï¸âƒ£ è¯»å–é…ç½®æ–‡ä»¶
# =====================================================
with open(projectRoot + "config.json", "r", encoding="utf-8") as f:
    config = json.load(f)

with open(projectRoot + "local.json", "r") as f:
    local = json.load(f)

activeClient = config["activeClient"]
chat_config = config[activeClient]
chat_local = local[activeClient]
emb_config = config[activeClient]
emb_local = local[activeClient]

glossaryFile = glossariesFolder + config["glossary"]

# æ¨å¯¼æ–‡ä»¶å
pklFile = binFolder + "glossary.pkl"
indexFile = binFolder + "glossary.index"

# åˆå§‹åŒ– embedding å®¢æˆ·ç«¯
emb_client_params = {"api_key": emb_local["key"]}
if "base_url" in emb_config:
    emb_client_params["base_url"] = emb_config["base_url"]
if "api_version" in emb_config:  # Azure
    emb_client_params["api_version"] = emb_config["api_version"]

embedding_client = OpenAI(**emb_client_params)

# åˆå§‹åŒ– chat å®¢æˆ·ç«¯
chat_client_params = {"api_key": chat_local["key"]}
if "base_url" in chat_config:
    chat_client_params["base_url"] = chat_config["base_url"]
if "api_version" in chat_config:
    chat_client_params["api_version"] = chat_config["api_version"]

chat_client = OpenAI(**chat_client_params)

# =====================================================
# 2ï¸âƒ£ åŠ è½½è¯åº“å’Œå‘é‡ç´¢å¼•
# =====================================================
try:
    glossary_data = pd.read_pickle(pklFile)
    print(f"âœ… æˆåŠŸåŠ è½½è¯åº“æ–‡ä»¶: {pklFile}")
    print(f"è¯åº“å…±æœ‰ {len(glossary_data)} æ¡è®°å½•")
except Exception as e:
    print(f"âŒ åŠ è½½ {pklFile} å¤±è´¥: {e}")
    exit(1)

try:
    index = faiss.read_index(indexFile)
    print(f"âœ… æˆåŠŸåŠ è½½ç´¢å¼•æ–‡ä»¶: {indexFile}")
except Exception as e:
    print(f"âŒ åŠ è½½ç´¢å¼•æ–‡ä»¶ {indexFile} å¤±è´¥: {e}")
    exit(1)

# =====================================================
# 3ï¸âƒ£ å®šä¹‰è¾…åŠ©å‡½æ•°
# =====================================================

def get_embedding(text: str):
    resp = embedding_client.embeddings.create(
        model=emb_config["model"],
        input=text
    )
    return np.array(resp.data[0].embedding, dtype="float32").reshape(1, -1)


def find_similar_terms(query: str, top_k: int = 3):
    """æŸ¥æ‰¾ä¸è¾“å…¥æ–‡æœ¬æœ€ç›¸ä¼¼çš„æœ¯è¯­"""
    query_emb = get_embedding(query)
    D, I = index.search(query_emb, top_k)
    results = []

    for dist, idx in zip(D[0], I[0]):
        term_row = glossary_data.iloc[idx]
        results.append({
            "zh": term_row["zh"],
            "translation": term_row["selected_text"] if "selected_text" in term_row else term_row.get("en", ""),
            "source_column": term_row.get("source_column", "N/A"),
            "distance": float(dist)
        })
    return results


def translate_with_glossary(query: str):
    """ç»“åˆ glossary ä¿¡æ¯çš„æ™ºèƒ½ç¿»è¯‘"""
    similar_terms = find_similar_terms(query)
    glossary_context = "\n".join(
        [f"{t['zh']} â†’ {t['translation']} ({t['source_column']})" for t in similar_terms]
    )

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä½›å­¦ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢çš„ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼Œ
å¹¶ä¸¥æ ¼å‚è€ƒä¸‹åˆ—æœ¯è¯­è¡¨è¿›è¡Œæœ¯è¯­ä¸€è‡´æ€§ç¿»è¯‘ã€‚

æœ¯è¯­è¡¨ï¼š
{glossary_context}

éœ€è¦ç¿»è¯‘çš„å¥å­ï¼š
{query}

è¯·è¾“å‡ºé«˜è´¨é‡è‹±æ–‡ç¿»è¯‘ã€‚
"""

    resp = chat_client.chat.completions.create(
        model=chat_config["model"],
        messages=[
            {"role": "system", "content": "You are a professional Buddhist translator."},
            {"role": "user", "content": prompt}
        ]
    )

    translation = resp.choices[0].message.content.strip()
    return translation, similar_terms


# =====================================================
# 4ï¸âƒ£ ä¸»ç¨‹åºå…¥å£
# =====================================================
if __name__ == "__main__":
    print("ğŸ“˜ AI ä½›å­¦æœ¯è¯­ç¿»è¯‘å™¨")
    print("è¾“å…¥ä¸­æ–‡å¥å­ï¼ˆè¾“å…¥ exit é€€å‡ºï¼‰ï¼š")

    while True:
        query = input("\n> ").strip()
        if not query:
            continue
        if query.lower() in ("exit", "quit", "bye"):
            break

        translation, terms = translate_with_glossary(query)

        print("\nğŸ”¹ ç¿»è¯‘ç»“æœï¼š")
        print(translation)

        print("\nğŸ”¸ å‚è€ƒæœ¯è¯­ï¼š")
        for t in terms:
            print(f"  {t['zh']} â†’ {t['translation']} ({t['source_column']})  [è·ç¦»: {t['distance']:.4f}]")
